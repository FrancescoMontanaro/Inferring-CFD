{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../Dataset/Flow signals/flow_signals_3.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = \"U\"\n",
    "naca_numbers = ['maximum_camber', 'maximum_camber_position', 'maximum_thickness']\n",
    "\n",
    "dataset = []\n",
    "with open(dataset_path, 'r') as dataset_file:\n",
    "  samples = json.load(dataset_file)\n",
    "  for sample in samples:\n",
    "    dataset.append({\n",
    "        \"features\": sample[\"features\"][feature_name],\n",
    "        \"labels\": list(sample[\"naca_numbers\"].values())\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biuldModel(input_shape):\n",
    "  # Sequential model - CNN 1D\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=input_shape),\n",
    "    keras.layers.Conv1D(filters=256, kernel_size=8, activation=tf.nn.relu),\n",
    "    keras.layers.AveragePooling1D(pool_size=2),\n",
    "    keras.layers.Dropout(0.05),\n",
    "    keras.layers.Conv1D(filters=128, kernel_size=8, activation=tf.nn.relu),\n",
    "    keras.layers.AveragePooling1D(pool_size=2),\n",
    "    keras.layers.Dropout(0.05),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=8, activation=tf.nn.relu),\n",
    "    keras.layers.AveragePooling1D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.05),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.05),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.05),\n",
    "    keras.layers.Dense(len(naca_numbers))\n",
    "  ])\n",
    "\n",
    "  # Compiling the model\n",
    "  model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the labels from the dataset\n",
    "labels = np.array([sample[\"labels\"] for sample in dataset])\n",
    "\n",
    "# Computing the distribution statistics of the labels\n",
    "naca_stats = {}\n",
    "for i in range(len(naca_numbers)):\n",
    "    max = np.max(labels[:,i])\n",
    "    min = np.min(labels[:,i])\n",
    "\n",
    "    naca_stats[naca_numbers[i]] = {\n",
    "        \"min\": min,\n",
    "        \"25%\": 0.25 * max,\n",
    "        \"50%\": 0.5 * max,\n",
    "        \"75%\": 0.75 * max,\n",
    "        \"max\": max\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200 # Number of training epochs\n",
    "split_percentage = 0.8 # Training and test set split percentage\n",
    "dataset_size = len(dataset) # Total number of samples available\n",
    "num_intervals = len(naca_stats[naca_numbers[0]].keys()) - 1 # Number of NACA intervals \n",
    "num_experiments = len(naca_numbers) * num_intervals # Total number of experiments\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10) # Early stopping with a patience of 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_results = []\n",
    "\n",
    "# Iterating over the NACA numbers\n",
    "for i in range(len(naca_numbers)):\n",
    "\n",
    "    # Extracting the distibution values of the NACA numbers\n",
    "    naca_values = [naca_value[1] for naca_value in list(naca_stats[naca_numbers[i]].items())]\n",
    "\n",
    "    # Iterating over the distribution ranges\n",
    "    for j in range(len(naca_values) - 1):\n",
    "        # Extracting the range of values of the NACA numbers for the i-th esperiment\n",
    "        range_values = (naca_values[j], naca_values[j+1])\n",
    "\n",
    "        # Training and Test set\n",
    "        train_dataset = [sample for sample in dataset if sample[\"labels\"][i] < range_values[0] or sample[\"labels\"][i] > range_values[1]]\n",
    "        test_dataset = [sample for sample in dataset if sample[\"labels\"][i] >= range_values[0] and sample[\"labels\"][i] <= range_values[1]]\n",
    "\n",
    "        # Extracting the features\n",
    "        train_features = np.array([sample[\"features\"] for sample in train_dataset])\n",
    "        test_features = np.array([sample[\"features\"] for sample in test_dataset])\n",
    "\n",
    "        # Extracting the labels\n",
    "        train_labels = np.array([sample[\"labels\"] for sample in train_dataset])\n",
    "        test_labels = np.array([sample[\"labels\"] for sample in test_dataset])\n",
    "\n",
    "        # Normalizing the data\n",
    "        mean = train_features.mean(axis=0)\n",
    "        std = train_features.std(axis=0)\n",
    "\n",
    "        normalized_train_data = (train_features - mean) / std\n",
    "        normalized_test_data = (test_features - mean) / std\n",
    "\n",
    "        # Expanding the dimensions of the training and test features\n",
    "        normalized_train_features = np.expand_dims(normalized_train_data, axis=2)\n",
    "        normalized_test_features = np.expand_dims(normalized_test_data, axis=2)\n",
    "\n",
    "        # Building the model\n",
    "        input_shape = [np.shape(normalized_train_features)[1], np.shape(normalized_train_features)[2]]\n",
    "        model = biuldModel(input_shape=input_shape)\n",
    "\n",
    "        # Training the model using the samples of the i-th experiment\n",
    "        model.fit(\n",
    "            normalized_train_features, \n",
    "            train_labels,\n",
    "            epochs=epochs,\n",
    "            validation_split = 0.2,\n",
    "            verbose = 0,\n",
    "            callbacks=[early_stopping]\n",
    "        )\n",
    "\n",
    "        # Extracting the values of loss, mean absolute error and mean square error for the i-th experiment\n",
    "        loss, mae = model.evaluate(normalized_test_features, test_labels, verbose = 0)\n",
    "\n",
    "        # Print status\n",
    "        experiment_number = (i + 1) * (j + 1)\n",
    "        print(f'Experiment {experiment_number}/{num_experiments} | NACA number excluded: {naca_numbers[i]} - {np.around(range_values, 3)} | Training samples: {train_features.shape[0]} | Loss: {round(loss, 6)} | MAE: {round(mae, 6)}')\n",
    "\n",
    "        # Saving the results of the current experiment into a dictionary\n",
    "        experiments_results.append({\"naca_number\": naca_numbers[i], \"range_values\": range_values, \"results\": [loss, mae]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot results with Bar chart\n",
    "def plotResults(naca_number, experiments_results):\n",
    "  fig = plt.figure()\n",
    "  ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "  range_values = [f'{round(result[\"range_values\"][0], 3), round(result[\"range_values\"][1], 3)}' for result in experiments_results]\n",
    "  data = [experiment_result[\"results\"][1] for experiment_result in experiments_results]\n",
    "\n",
    "  ax.bar(range_values, data)\n",
    "\n",
    "  plt.xlabel(\"Test set range of values of NACA number\")\n",
    "  plt.ylabel(\"Mean Absolute Error\")\n",
    "  plt.title(naca_number.replace(\"_\", \" \"))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "for naca_number in naca_numbers:\n",
    "    result = [experiment_result for experiment_result in experiments_results if experiment_result[\"naca_number\"] == naca_number]\n",
    "    plotResults(naca_number, result)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
