{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500 # Number of training epochs\n",
    "batch_size = 16 # Batch size\n",
    "split_percentage = 0.8 # Training and test set splitting percentage\n",
    "validation_split = 0.2 # Validation set percentage\n",
    "early_stopping_patience = 15 # Number of epochs of patience before triggering early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE ME\n",
    "dataset_path = \"../Dataset/Flow signals/ND_signals/3d_flow_signals_1.json\" # Dataset path\n",
    "flow_quantity = \"p\" # Flow quantity to be used as feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naca_numbers = ['maximum_camber', 'maximum_camber_position', 'maximum_thickness']\n",
    "\n",
    "dataset = []\n",
    "with open(dataset_path, 'r') as dataset_file:\n",
    "  samples = json.load(dataset_file)\n",
    "  for sample in samples:\n",
    "    dataset.append({\n",
    "        \"features\": sample[\"features\"][flow_quantity],\n",
    "        \"labels\": list(sample[\"naca_numbers\"].values())\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the dataset\n",
    "np.random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the number of training samples according to the splitting percentage\n",
    "num_training_samples = int(np.floor(split_percentage * len(dataset)))\n",
    "\n",
    "# Extracting the training and test set\n",
    "training_set, test_set = dataset[:num_training_samples], dataset[num_training_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the training features and labels\n",
    "train_features = np.array([sample[\"features\"] for sample in training_set])\n",
    "train_labels = np.array([sample[\"labels\"] for sample in training_set])\n",
    "\n",
    "# Extracting the test features and labels\n",
    "test_features = np.array([sample[\"features\"] for sample in test_set])\n",
    "test_labels = np.array([sample[\"labels\"] for sample in test_set])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the mean and standard deviation of the training features\n",
    "mean = train_features.mean(axis=0)\n",
    "std = train_features.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the training and test features w.r.t. the training statistics\n",
    "normalized_train_features = (train_features - mean) / std\n",
    "normalized_test_features = (test_features - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a random sample\n",
    "plt.plot(normalized_train_features[random.choice([0, len(normalized_train_features)-1])])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST MODEL FOR 1D SIGNALS\n",
    "def buildModel():\n",
    "  # Sequential model - CNN 1D\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=np.shape(normalized_train_features)[1:]),\n",
    "    keras.layers.Conv1D(filters=30, kernel_size=3, activation=tf.nn.tanh),\n",
    "    keras.layers.AveragePooling1D(pool_size=2),\n",
    "    keras.layers.Dropout(0.01),\n",
    "    keras.layers.Conv1D(filters=20, kernel_size=3, activation=tf.nn.tanh),\n",
    "    keras.layers.AveragePooling1D(pool_size=2),\n",
    "    keras.layers.Dropout(0.01),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(20, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(10, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(len(naca_numbers))\n",
    "  ])\n",
    "\n",
    "  # Compiling the model\n",
    "  model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buildModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping with a predefined patience\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=early_stopping_patience)\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    normalized_train_features, \n",
    "    train_labels,\n",
    "    epochs=epochs,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the metrics of training and validation\n",
    "def plotHistory(history, training_metric, validation_metric, ylabel):\n",
    "  plt.plot(history.history[training_metric], label=training_metric)\n",
    "  plt.plot(history.history[validation_metric], label=validation_metric)\n",
    "  plt.ylim([0, np.max(history.history[training_metric] + history.history[validation_metric])])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel(ylabel)\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHistory(history, 'loss', 'val_loss', \"Loss\")\n",
    "plotHistory(history, 'mae', 'val_mae', \"Mean Absolute Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the predictions of the test set\n",
    "predictions = model.predict(normalized_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the classification accuracy\n",
    "def computeAccuracy():\n",
    "    \n",
    "    # Creating an array to save the results\n",
    "    accuracy = np.zeros(len(naca_numbers))\n",
    "\n",
    "    for idx in range(len(naca_numbers)):\n",
    "        # Converting the NACA values to the closest interger\n",
    "        naca_predictions = np.array([round(prediction) for prediction in predictions[:,idx]])\n",
    "        naca_labels = np.array([round(label) for label in test_labels[:,idx]])\n",
    "\n",
    "        # Extracting the samples correctly classified\n",
    "        correctly_classified = np.where(np.equal(naca_predictions, naca_labels))\n",
    "\n",
    "        # Computing the classification accuracy of the current NACA number\n",
    "        accuracy[idx] = np.shape(correctly_classified)[1] / len(naca_labels)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the classification accuracy\n",
    "accuracy = computeAccuracy()\n",
    "\n",
    "# Computing the regression errors: MSE and MAE\n",
    "loss, mae = model.evaluate(normalized_test_features, test_labels, verbose=0)\n",
    "\n",
    "print(\"REGRESSION\")\n",
    "print(f\" - Loss (Mean Square Error) --> {loss}\")\n",
    "print(f\" - Mean Absolute Error --> {mae}\")\n",
    "\n",
    "\n",
    "print(\"\\nCLASSIFICATION\")\n",
    "print(f\" - Accuracy --> {np.mean(accuracy)}\")\n",
    "for i in range(len(naca_numbers)):\n",
    "    print(f\"   â€¢ {naca_numbers[i]} --> {accuracy[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the predictions of the test set\n",
    "predictions = model.predict(normalized_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the predicted values\n",
    "def plotPredictions(test_labels, test_predictions, label, color):\n",
    "  plt.scatter(test_labels, test_predictions, label=label, color=color)\n",
    "  plt.xlabel('True values')\n",
    "  plt.ylabel('Predictions')\n",
    "  plt.axis('equal')\n",
    "  plt.axis('square')\n",
    "  plt.xlim([0, np.max(test_labels)])\n",
    "  plt.ylim([0, np.max(test_labels)])\n",
    "  plt.plot([0, 100], [0, 100], color=\"black\")\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"blue\", \"green\", \"orange\"]\n",
    "\n",
    "# Plotting the obtained results\n",
    "for i in range(len(naca_numbers)):\n",
    "  plotPredictions(test_labels[:,i], predictions[:,i], label=naca_numbers[i], color=colors[i])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
