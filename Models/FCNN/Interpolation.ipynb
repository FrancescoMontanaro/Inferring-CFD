{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE ME\n",
    "dataset_path = \"../Dataset/Regional averages/ND_regional_averages/1d_regional_averages_-1c.json\"\n",
    "feature_name = \"p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naca_numbers = ['maximum_camber', 'maximum_camber_position', 'maximum_thickness']\n",
    "\n",
    "dataset = []\n",
    "with open(dataset_path, 'r') as dataset_file:\n",
    "  samples = json.load(dataset_file)\n",
    "  for sample in samples:\n",
    "    dataset.append({\n",
    "        \"features\": sample[\"features\"][feature_name],\n",
    "        \"labels\": list(sample[\"naca_numbers\"].values())\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST MODEL FOR REGIONAL AVERAGES\n",
    "def buildModel(input_shape):\n",
    "  # Sequential Model\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=input_shape),\n",
    "    keras.layers.Dense(30, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(20, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(10, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(len(naca_numbers))\n",
    "  ])\n",
    "\n",
    "  # Compiling the model\n",
    "  model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the classification accuracy\n",
    "def computeAccuracy(predictions, test_labels):\n",
    "    # Creating an array to save the results\n",
    "    accuracy = np.zeros(len(naca_numbers))\n",
    "\n",
    "    for idx in range(len(naca_numbers)):\n",
    "        # Converting the NACA values to the closest interger\n",
    "        naca_predictions = np.array([round(prediction) for prediction in predictions[:,idx]])\n",
    "        naca_labels = np.array([round(label) for label in test_labels[:,idx]])\n",
    "\n",
    "        # Extracting the samples correctly classified\n",
    "        correctly_classified = np.where(np.equal(naca_predictions, naca_labels))\n",
    "\n",
    "        # Computing the classification accuracy of the current NACA number\n",
    "        accuracy[idx] = np.shape(correctly_classified)[1] / len(naca_labels)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMAE(predictions, test_labels):\n",
    "    # Creating an array to save the results\n",
    "    maes = np.zeros(len(naca_numbers))\n",
    "\n",
    "    # Computing the Mean absolute error\n",
    "    for idx in range(len(naca_numbers)):\n",
    "        # Computing the Mean Absolute Error of the current NACA number\n",
    "        mae = np.mean(np.absolute(predictions[:,idx] - test_labels[:,idx]))\n",
    "\n",
    "        # Adding the result to the array\n",
    "        maes[idx] = mae\n",
    "\n",
    "    return maes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500 # Number of training epochs\n",
    "step_size = 100 # Increment of samples per experiment\n",
    "split_percentage = 0.8 # Training and test set split percentage\n",
    "validation_split = 0.2 # Validation set percentage\n",
    "dataset_size = len(dataset) # Total number of samples available\n",
    "num_experiments = int(np.ceil(dataset_size / step_size)) # Total number of experiments\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=15) # Early stopping with a patience of 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_mae, experiments_accuracy = np.zeros((num_experiments, 2)), np.zeros((num_experiments, 2))\n",
    "\n",
    "# Iterating over the number of the experiments\n",
    "for idx in range(num_experiments):\n",
    "  # Extracting the numer of samples to use for the i-th experiment\n",
    "  num_samples = ((idx + 1) * step_size) \n",
    "  num_samples = num_samples if num_samples < dataset_size else dataset_size\n",
    "\n",
    "  # Extracting the samples to be used in the experiment\n",
    "  experiment_dataset = random.sample(dataset, num_samples)\n",
    "\n",
    "  # Computing the number of training samples according to the splitting percentage\n",
    "  num_training_samples = int(np.floor(split_percentage * len(experiment_dataset)))\n",
    "\n",
    "  # Extracting the training and test set of the current experiment\n",
    "  training_set, test_set = experiment_dataset[:num_training_samples], experiment_dataset[num_training_samples:]\n",
    "\n",
    "  # Extracting the training features and labels\n",
    "  train_features = np.array([sample[\"features\"] for sample in training_set])\n",
    "  train_labels = np.array([sample[\"labels\"] for sample in training_set])\n",
    "\n",
    "  # Extracting the test features and labels\n",
    "  test_features = np.array([sample[\"features\"] for sample in test_set])\n",
    "  test_labels = np.array([sample[\"labels\"] for sample in test_set])\n",
    "\n",
    "  # Normalizing the data\n",
    "  mean = train_features.mean(axis=0)\n",
    "  std = train_features.std(axis=0)\n",
    "\n",
    "  normalized_train_features = (train_features - mean) / std\n",
    "  normalized_test_features = (test_features - mean) / std\n",
    "\n",
    "  # Building the model\n",
    "  model = buildModel(input_shape=np.shape(normalized_train_features)[1:])\n",
    "\n",
    "  # Training the model using the samples of the i-th experiment\n",
    "  model.fit(\n",
    "    normalized_train_features, \n",
    "    train_labels,\n",
    "    epochs=epochs,\n",
    "    validation_split=validation_split,\n",
    "    verbose=0,\n",
    "    callbacks=[early_stopping]\n",
    "  )\n",
    "\n",
    "  # Computing the predictions of the test set\n",
    "  predictions = model.predict(normalized_test_features)\n",
    "\n",
    "  # Computing the regression Mean Absolute Error\n",
    "  mae = computeMAE(predictions, test_labels)\n",
    "  mae = np.mean(mae)\n",
    "\n",
    "  # Computing the classification accuracy\n",
    "  accuracy = computeAccuracy(predictions, test_labels)\n",
    "  accuracy = np.mean(accuracy)\n",
    "\n",
    "  # Display progress\n",
    "  print(f'Experiment {idx + 1}/{num_experiments} | Number of samples: {len(experiment_dataset)} | Regression MAE: {mae} | Classification Accuracy: {accuracy}')\n",
    "\n",
    "  # Adding the experiment's results to the results list\n",
    "  experiments_mae[idx, :] = [num_samples, mae]\n",
    "  experiments_accuracy[idx, :]= [num_samples, accuracy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(experiments_mae)\n",
    "print(experiments_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the moving average of the and array\n",
    "def movingAverage(data, window):\n",
    "    moving_average = np.convolve(data, np.ones(window), 'valid') / window\n",
    "    return moving_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the results\n",
    "def plot_results(data, y_label):\n",
    "    x = data[:,0]\n",
    "    y = data[:,1]\n",
    "\n",
    "    # Computing the moving average of the obtained results\n",
    "    window = 3\n",
    "    moving_average = movingAverage(y, window)\n",
    "\n",
    "    # Plotting the results\n",
    "    plt.plot(x[(window-1):], moving_average, color=\"red\")\n",
    "    plt.scatter(x, y, color=\"blue\")\n",
    "\n",
    "    plt.legend([f'Moving Average {window}'], loc='upper right')\n",
    "    plt.xlabel(\"Training set size\")\n",
    "    plt.ylabel(y_label)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(experiments_mae, \"Regression - Mean Absolute Error\")\n",
    "plot_results(experiments_accuracy, \"Classification - Accuracy\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
