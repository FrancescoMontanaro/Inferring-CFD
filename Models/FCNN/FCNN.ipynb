{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8332b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8528f0c",
   "metadata": {},
   "source": [
    "### Constants and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb73629",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500 # Number of training epochs\n",
    "batch_size = 24 # Batch size\n",
    "split_percentage = 0.8 # Training and test set splitting percentage\n",
    "validation_split = 0.2 # Validation set percentage\n",
    "early_stopping_patience = 15 # Number of epochs of patience before triggering early stopping\n",
    "naca_numbers = ['maximum_camber', 'maximum_camber_position', 'maximum_thickness'] # NACA numbers to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dad1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE ME\n",
    "dataset_path = \"../Dataset/Definitivo/NACA prediction/Arrival times/arrival_times.npz\" # Dataset path\n",
    "flow_quantity = \"distribution_statistics\" # Flow quantity to be used as feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0974dd",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f7a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "dataset = np.load(dataset_path)\n",
    "dataset = list(zip(dataset[flow_quantity], dataset[\"naca_numbers\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273ecb6e",
   "metadata": {},
   "source": [
    "### Shuffling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93213a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the dataset\n",
    "np.random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26d213c",
   "metadata": {},
   "source": [
    "### Features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe4e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the features and the labels from the dataset\n",
    "X, Y = zip(*dataset)\n",
    "X, Y = np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211e941d",
   "metadata": {},
   "source": [
    "### Training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ead732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the number of training samples according to the splitting percentage\n",
    "num_training_samples = int(np.floor(split_percentage * len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3240bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the training features and labels\n",
    "X_train, Y_train = X[:num_training_samples], Y[:num_training_samples]\n",
    "\n",
    "# Extracting the test features and labels\n",
    "X_test, Y_test = X[num_training_samples:], Y[num_training_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3d844d",
   "metadata": {},
   "source": [
    "### Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a389c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the mean and standard deviation of the training features\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556346c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize samples\n",
    "def normalize(x):\n",
    "    x = (x - mean) / std\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15721cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a random sample\n",
    "try:\n",
    "    choice = np.random.randint(0, (len(X_train)-1))\n",
    "    plt.title(f\"NACA: {''.join(str(int(y)) for y in Y_train[choice])}\")\n",
    "    plt.ylabel(flow_quantity)\n",
    "    plt.plot(X_train[choice])\n",
    "except:\n",
    "    print(\"Features cannot be displayed\")\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586bfdc1",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fe46a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST MODEL FOR 1D FEATURES\n",
    "def buildModel():\n",
    "  # Sequential Model\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=np.shape(X_train)[1]),\n",
    "    keras.layers.Lambda(normalize),\n",
    "    keras.layers.Dense(30, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(20, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(10, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(len(naca_numbers))\n",
    "  ])\n",
    "\n",
    "  # Compiling the model\n",
    "  model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555ba021",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buildModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f169cb56",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51a7905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping with a predefined patience\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=early_stopping_patience,\n",
    "    restore_best_weights=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    Y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=validation_split,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb653d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the metrics of training and validation\n",
    "def plotHistory(history, training_metric, validation_metric, ylabel):\n",
    "  plt.plot(history.history[training_metric], label=training_metric)\n",
    "  plt.plot(history.history[validation_metric], label=validation_metric)\n",
    "  plt.ylim([0, np.max(history.history[training_metric] + history.history[validation_metric])])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel(ylabel)\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae357e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHistory(history, 'loss', 'val_loss', \"Loss\")\n",
    "plotHistory(history, 'mae', 'val_mae', \"Mean Absolute Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1683c78",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3634b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the predictions of the test set\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d32c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the classification accuracy\n",
    "def classificationMetrics(predictions, labels):\n",
    "    # Creating an array to save the results\n",
    "    accuracy = np.zeros(len(naca_numbers))\n",
    "\n",
    "    for idx in range(len(naca_numbers)):\n",
    "        # Converting the NACA values to the closest interger\n",
    "        naca_predictions = np.array([round(prediction) for prediction in predictions[:,idx]])\n",
    "        naca_labels = np.array([round(label) for label in labels[:,idx]])\n",
    "\n",
    "        # Extracting the samples correctly classified\n",
    "        correctly_classified = np.where(np.equal(naca_predictions, naca_labels))\n",
    "\n",
    "        # Computing the classification accuracy of the current NACA number\n",
    "        accuracy[idx] = np.shape(correctly_classified)[1] / len(naca_labels)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eec9d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressionMetrics(predictions, labels):\n",
    "    # Creating an array to save the results\n",
    "    mses, maes = np.zeros(len(naca_numbers)), np.zeros(len(naca_numbers))\n",
    "\n",
    "    # Computing the Mean absolute error\n",
    "    for idx in range(len(naca_numbers)):\n",
    "        # Computing the Mean Absolute Error of the current NACA number\n",
    "        mae = np.mean(np.absolute(predictions[:,idx] - labels[:,idx]))\n",
    "        mse = ((predictions[:,idx] - labels[:,idx])**2).mean(axis=0)\n",
    "\n",
    "        # Adding the result to the array\n",
    "        mses[idx], maes[idx] = mse, mae\n",
    "\n",
    "    return mses, maes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bd2694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the classification accuracy\n",
    "accuracy = classificationMetrics(predictions, Y_test)\n",
    "\n",
    "# Computing the regression errors: MSE and MAE\n",
    "mse, mae = regressionMetrics(predictions, Y_test)\n",
    "\n",
    "# Displaying results\n",
    "print(f\"Mean Square Error (Loss) --> {np.mean(mse.flatten())}\")\n",
    "for i in range(len(naca_numbers)):\n",
    "    print(f\"  • {naca_numbers[i]}: {np.mean(mse[:,i])}\")\n",
    "\n",
    "print(f\"\\nMean Absolute Error --> {np.mean(mae.flatten())}\")\n",
    "for i in range(len(naca_numbers)):\n",
    "    print(f\"  • {naca_numbers[i]}: {np.mean(mae[:,i])}\")\n",
    "\n",
    "print(f\"\\nClassification Accuracy --> {np.mean(accuracy.flatten())}\")\n",
    "for i in range(len(naca_numbers)):\n",
    "    print(f\"  • {naca_numbers[i]}: {np.mean(accuracy[:,i])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a929dd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the predicted values\n",
    "def plotPredictions(test_labels, test_predictions, label, color):\n",
    "  plt.scatter(test_labels, test_predictions, label=label, color=color)\n",
    "  plt.xlabel('True values')\n",
    "  plt.ylabel('Predictions')\n",
    "  plt.axis('equal')\n",
    "  plt.axis('square')\n",
    "  plt.xlim([0, np.max(test_labels)])\n",
    "  plt.ylim([0, np.max(test_labels)])\n",
    "  plt.plot([0, 100], [0, 100], color=\"black\")\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae80cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"blue\", \"green\", \"orange\"]\n",
    "\n",
    "# Plotting the obtained results\n",
    "for i in range(len(naca_numbers)):\n",
    "  plotPredictions(Y_test[:,i], predictions[:,i], label=naca_numbers[i], color=colors[i])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
