{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8332b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0974dd",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dad1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE ME\n",
    "dataset_path = \"../Dataset/Regional arrival times/regional_arrival_times_1.json\"\n",
    "feature_name = \"arrival_times\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f7a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "naca_numbers = ['maximum_camber', 'maximum_camber_position', 'maximum_thickness']\n",
    "\n",
    "dataset = []\n",
    "with open(dataset_path, 'r') as dataset_file:\n",
    "  samples = json.load(dataset_file)\n",
    "  for sample in samples:\n",
    "    dataset.append({\n",
    "        \"features\": sample[\"features\"][feature_name],\n",
    "        \"labels\": list(sample[\"naca_numbers\"].values())\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273ecb6e",
   "metadata": {},
   "source": [
    "### Shuffling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93213a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the dataset\n",
    "np.random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211e941d",
   "metadata": {},
   "source": [
    "### Training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ead732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training and test set splitting percentage\n",
    "split_percentage = 0.8\n",
    "\n",
    "# Computing the number of training samples according to the splitting percentage\n",
    "num_training_samples = int(np.floor(split_percentage * len(dataset)))\n",
    "\n",
    "# Extracting the training and test set\n",
    "training_set, test_set = dataset[:num_training_samples], dataset[num_training_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3240bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the training features and labels\n",
    "train_features = np.array([sample[\"features\"] for sample in training_set])\n",
    "train_labels = np.array([sample[\"labels\"] for sample in training_set])\n",
    "\n",
    "# Extracting the test features and labels\n",
    "test_features = np.array([sample[\"features\"] for sample in test_set])\n",
    "test_labels = np.array([sample[\"labels\"] for sample in test_set])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3d844d",
   "metadata": {},
   "source": [
    "### Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a389c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the mean and standard deviation of the training features\n",
    "mean = train_features.mean(axis=0)\n",
    "std = train_features.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dd9b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the training and test features w.r.t. the training statistics\n",
    "normalized_train_features = (train_features - mean) / std\n",
    "normalized_test_features = (test_features - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15721cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a random sample\n",
    "plt.plot(normalized_train_features[random.choice([0, len(normalized_train_features)-1])])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586bfdc1",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aca39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST MODEL FOR REGIONAL AVERAGES\n",
    "def buildModel1():\n",
    "  # Sequential Model\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=[np.shape(normalized_train_features)[1]]),\n",
    "    keras.layers.Dropout(0.01),\n",
    "    keras.layers.Dense(176, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.01),\n",
    "    keras.layers.Dense(208, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.01),\n",
    "    keras.layers.Dense(240, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.01),\n",
    "    keras.layers.Dense(240, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.01),\n",
    "    keras.layers.Dense(len(naca_numbers))\n",
    "  ])\n",
    "\n",
    "  # Compiling the model\n",
    "  model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27502ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST MODEL FOR ARRIVAL TIMES\n",
    "def buildModel2():\n",
    "  # Sequential Model\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=[np.shape(normalized_train_features)[1]]),\n",
    "    keras.layers.Dropout(0.03),\n",
    "    keras.layers.Dense(96, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.03),\n",
    "    keras.layers.Dense(80, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.03),\n",
    "    keras.layers.Dense(48, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.03),\n",
    "    keras.layers.Dense(224, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.03),\n",
    "    keras.layers.Dense(len(naca_numbers))\n",
    "  ])\n",
    "\n",
    "  # Compiling the model\n",
    "  model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0634a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST MODEL FOR REGIONAL ARRIVAL TIMES\n",
    "def buildModel3():\n",
    "  # Sequential Model\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=[np.shape(normalized_train_features)[1]]),\n",
    "    keras.layers.Dropout(0.01),\n",
    "    keras.layers.Dense(240, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.01),\n",
    "    keras.layers.Dense(80, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.01),\n",
    "    keras.layers.Dense(224, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.01),\n",
    "    keras.layers.Dense(len(naca_numbers))\n",
    "  ])\n",
    "\n",
    "  # Compiling the model\n",
    "  model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555ba021",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buildModel3()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f169cb56",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51a7905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the number of training epochs\n",
    "epochs = 200\n",
    "\n",
    "# Early stopping with a patience of 10 epochs\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    normalized_train_features, \n",
    "    train_labels,\n",
    "    epochs=epochs,\n",
    "    validation_split = 0.2,\n",
    "    verbose = 2,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb653d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the metrics of training and validation\n",
    "def plotHistory(history, training_metric, validation_metric, ylabel):\n",
    "  plt.plot(history.history[training_metric], label=training_metric)\n",
    "  plt.plot(history.history[validation_metric], label=validation_metric)\n",
    "  plt.ylim([0, np.max(history.history[training_metric] + history.history[validation_metric])])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel(ylabel)\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae357e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHistory(history, 'loss', 'val_loss', \"Loss\")\n",
    "plotHistory(history, 'mae', 'val_mae', \"Mean Absolute Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1683c78",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c27086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the values of loss, mean absolute error and mean square error\n",
    "loss, mae = model.evaluate(normalized_test_features, test_labels, verbose = 0)\n",
    "\n",
    "print(\"RESULTS\")\n",
    "print(f\"Loss (Mean Square Error) --> {loss}\")\n",
    "print(f\"Mean Absolute Error --> {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ad1a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the predictions of the test set\n",
    "predictions = model.predict(normalized_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a929dd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the predicted values\n",
    "def plotPredictions(test_labels, test_predictions, label, color):\n",
    "  plt.scatter(test_labels, test_predictions, label=label, color=color)\n",
    "  plt.xlabel('True values')\n",
    "  plt.ylabel('Predictions')\n",
    "  plt.axis('equal')\n",
    "  plt.axis('square')\n",
    "  plt.xlim([0, 1])\n",
    "  plt.ylim([0, 1])\n",
    "  plt.plot([0, 1], [0, 1], color=\"black\")\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae80cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"blue\", \"green\", \"orange\"]\n",
    "\n",
    "# Plotting the obtained results\n",
    "for i in range(len(naca_numbers)):\n",
    "  plotPredictions(test_labels[:,i], predictions[:,i], label=naca_numbers[i], color=colors[i])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
